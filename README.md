
# ğŸš¦ Real-Time Traffic Congestion Detection

This project demonstrates how to detect road traffic congestion in **real-time** using  
**Kafka + PySpark Structured Streaming + Streamlit**.  

Traffic data is simulated from a CSV file, processed in streaming mode, and displayed in a live dashboard.

---

## ğŸ“‚ Project Structure

```

traffic-rt/
â”œâ”€ docker-compose.yml
â”œâ”€ data/
â”‚  â””â”€ traffic\_sample.csv
â”œâ”€ producer/
â”‚  â”œâ”€ producer.py
â”‚  â”œâ”€ Dockerfile
â”‚  â””â”€ requirements.txt
â”œâ”€ spark/
â”‚  â”œâ”€ app/traffic\_stream.py
â”‚  â””â”€ requirements.txt
â””â”€ dashboard/
â”œâ”€ app.py
â”œâ”€ Dockerfile
â””â”€ requirements.txt

````

---

## âš™ï¸ Configuration

**Producer**
- `CSV_PATH` â€“ path to the CSV file with traffic data  
- `SPEED_FACTOR` â€“ playback speed factor (e.g. `60` = 1 minute per second)  
- `LOOP=1` â€“ enable replay loop  
- `USE_NOW=1` â€“ replace timestamps with current time (important for Spark watermarking)  

**Spark**
- `CONGESTION_THRESHOLD` â€“ threshold for congestion detection (default: `25`)  
- `SOURCE_TOPIC`, `AGG_TOPIC`, `ALERT_TOPIC` â€“ Kafka topics used in the pipeline  

---

## â–¶ï¸ How to Run

1. Clone the repository:
```bash
git clone https://github.com/cyptrix12/Kafka-traffic.git
cd traffic-rt
````

2. Start the containers:

```bash
docker compose up --build
```

This will start:

* `kafka` â€“ Redpanda broker (Kafka-compatible)
* `producer` â€“ streams CSV traffic data into Kafka
* `spark` â€“ PySpark Structured Streaming job detecting congestion
* `dashboard` â€“ Streamlit web app

3. Open the dashboard:
   ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---
